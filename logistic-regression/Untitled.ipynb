{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c90df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.train_accuracies = []\n",
    "\n",
    "    def fit(self, x, y, epochs):\n",
    "        x = self._transform_x(x)\n",
    "        y = self._transform_y(y)\n",
    "\n",
    "        self.weights = np.zeros(x.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(epochs):\n",
    "            x_dot_weights = np.matmul(self.weights, x.transpose()) + self.bias\n",
    "            pred = self._sigmoid(x_dot_weights)\n",
    "            loss = self.compute_loss(y, pred)\n",
    "            error_w, error_b = self.compute_gradients(x, y, pred)\n",
    "            self.update_model_parameters(error_w, error_b)\n",
    "\n",
    "            pred_to_class = [1 if p > 0.5 else 0 for p in pred]\n",
    "            self.train_accuracies.append(accuracy_score(y, pred_to_class))\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # binary cross entropy\n",
    "        y_zero_loss = y_true * np.log(y_pred + 1e-9)\n",
    "        y_one_loss = (1-y_true) * np.log(1 - y_pred + 1e-9)\n",
    "        return -np.mean(y_zero_loss + y_one_loss)\n",
    "\n",
    "    def compute_gradients(self, x, y_true, y_pred):\n",
    "        # derivative of binary cross entropy\n",
    "        difference =  y_pred - y_true\n",
    "        gradient_b = np.mean(difference)\n",
    "        gradients_w = np.matmul(x.transpose(), difference)\n",
    "        gradients_w = np.array([np.mean(grad) for grad in gradients_w])\n",
    "\n",
    "        return gradients_w, gradient_b\n",
    "\n",
    "    def update_model_parameters(self, error_w, error_b):\n",
    "        self.weights = self.weights - 0.1 * error_w\n",
    "        self.bias = self.bias - 0.1 * error_b\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_dot_weights = np.matmul(x, self.weights.transpose()) + self.bias\n",
    "        probabilities = self._sigmoid(x_dot_weights)\n",
    "        return [1 if p > 0.5 else 0 for p in probabilities]\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return np.array([self._sigmoid_function(value) for value in x])\n",
    "\n",
    "    def _sigmoid_function(self, x):\n",
    "        if x >= 0:\n",
    "            z = np.exp(-x)\n",
    "            return 1 / (1 + z)\n",
    "        else:\n",
    "            z = np.exp(x)\n",
    "            return z / (1 + z)\n",
    "\n",
    "    def _transform_x(self, x):\n",
    "        x = copy.deepcopy(x)\n",
    "        return x.values\n",
    "\n",
    "    def _transform_y(self, y):\n",
    "        y = copy.deepcopy(y)\n",
    "        return y.values.reshape(y.shape[0], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
